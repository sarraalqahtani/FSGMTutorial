# FSGMTutorial
The original paper can be found at:
https://arxiv.org/abs/1412.6572

**FSGM**
We begin with deriving a simple way of constructing an adversarial example around an input (x, y).
Supppose we denote our neural network by a function f : X → {0, . . . , 9}.
Suppose we want to find a small perturbation ∆ of x such that the neural network f assigns a label
different from y to x+∆. To find such a ∆, we want to increase the cross-entropy loss of the network f
at (x, y); in other words, we want to take a small step ∆ along which the cross-entropy loss increases,
thus causing a misclassification. We can write this as a gradient ascent update, and to ensure that we
only take a small step, we can just use the sign of each coordinate of the gradient. The final algorithm
is this:
x˜ = x + ε · sign(∇L(f, x, y)),
where L is the cross-entropy loss.

First, implement the Fast Gradient Sign Method (FGSM) for the neural network given to you in the last tutorial. Then,
evaluate and report the accuracy of the neural network on adversarial examples. This is computed
as follows – 
for each test example x(i)
, generate an adversarial example ˜x(i)
for ε= 0.1. 
The neural
network is correct if it predicts y(i) on ˜x(i) and wrong otherwise.

**New Method and Pseudocode (Optional)**
Next, design your own method to find adversarial examples. Your algorithm should take as input a
labeled example (x, y) and a perturbation amount ε, and output an adversarial example ˜x such that
the infinity norm of the difference between x and ˜x, is at most ε.
Describe your algorithm, and write down clear pseudocode for it.

**Experimental results**
A (clearly labeled) table or graph of results showing the accuracy of the given neural network on adversarial examples generated by your algorithm vs. the fast gradient sign method on the given MNIST as a function of ε. Report the accuracy on adversarial examples for ε= 0.05, 0.1, 0.15, 0.2. For
any strategy with randomness, you should do several experiments and give error bars – give all relevant
details.
The pseudocode and experimental details must contain all information needed to reproduce the results.

**Critical evaluation**
Is your method a clear improvement over FSGM? Is there further scope for improvement? What would you like to try next?
